Index: src/main/java/chapter01/Source_Test_Kafka.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/main/java/chapter01/Source_Test_Kafka.java b/src/main/java/chapter01/Source_Test_Kafka.java
--- a/src/main/java/chapter01/Source_Test_Kafka.java	
+++ b/src/main/java/chapter01/Source_Test_Kafka.java	
@@ -1,0 +1,30 @@
+package chapter01;
+
+import org.apache.flink.api.common.restartstrategy.RestartStrategies;
+import org.apache.flink.api.common.serialization.SimpleStringSchema;
+import org.apache.flink.streaming.api.datastream.DataStreamSource;
+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
+import org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer;
+
+import java.util.Properties;
+
+public class Source_Test_Kafka {
+    public static void main(String[] args) throws Exception {
+        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
+        env.setRestartStrategy(RestartStrategies.noRestart());
+
+        //5, 从kafka读取数据
+        Properties properties = new Properties();
+        properties.setProperty("bootstrap.servers","localhost:60003");
+        properties.setProperty("group.id", "consumer-group");
+        properties.setProperty("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
+        properties.setProperty("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
+        properties.setProperty("auto.offset.reset", "latest");
+
+        DataStreamSource<String> kafkaStream = env.addSource(new FlinkKafkaConsumer<String>("clicks", new SimpleStringSchema(), properties));
+
+
+        kafkaStream.print();
+        env.execute();
+    }
+}
\ No newline at end of file
Index: src/main/java/Chapter02_Customer_Source/SourceCustomerTest.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/main/java/Chapter02_Customer_Source/SourceCustomerTest.java b/src/main/java/Chapter02_Customer_Source/SourceCustomerTest.java
--- a/src/main/java/Chapter02_Customer_Source/SourceCustomerTest.java	
+++ b/src/main/java/Chapter02_Customer_Source/SourceCustomerTest.java	
@@ -1,0 +1,24 @@
+package Chapter02_Customer_Source;
+
+
+//通过添加AddSource调用一个自定义的Source作为源
+
+import org.apache.flink.streaming.api.datastream.DataStreamSource;
+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
+
+public class SourceCustomerTest {
+    public static void main(String[] args) throws Exception {
+        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
+        env.setParallelism(4);
+
+        //自定义SourceFunction
+//        DataStreamSource<Event> customersource = env.addSource(new ClickSource());
+
+        //定义一个并行度为4的 ParallelismSourceFunction
+          DataStreamSource<Event> customersource = env.addSource(new Parallelism_Source()).setParallelism(2);
+
+        customersource.print();
+
+        env.execute();
+    }
+}
Index: src/main/java/Chapter02_Customer_Source/Parallelism_Source.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/main/java/Chapter02_Customer_Source/Parallelism_Source.java b/src/main/java/Chapter02_Customer_Source/Parallelism_Source.java
--- a/src/main/java/Chapter02_Customer_Source/Parallelism_Source.java	
+++ b/src/main/java/Chapter02_Customer_Source/Parallelism_Source.java	
@@ -1,0 +1,35 @@
+package Chapter02_Customer_Source;
+
+import Chapter02_Customer_Source.Event;
+import org.apache.flink.streaming.api.functions.source.ParallelSourceFunction;
+
+import java.util.Calendar;
+import java.util.Random;
+
+public class Parallelism_Source implements ParallelSourceFunction<Event> {
+    //声明标识位
+    private boolean running = true;
+    @Override
+    public void run(SourceContext<Event> ctx) throws Exception {
+
+        //随机生成器
+        Random random = new Random();
+        //定义字段选取的数据集
+        String[] users = {"Ling","Bob","FakeBob"};
+        String[] urls = {"./home","./cart","./fav","./prod?id=100","./prod?id=200"};
+
+
+        //循环生成数据
+        while (running){
+            String user = users[random.nextInt(users.length)];
+            String url = urls[random.nextInt(urls.length)];
+            Long timestamp = Calendar.getInstance().getTimeInMillis();
+            ctx.collect(new Event(user,url,timestamp));
+            Thread.sleep(1000L);
+        }
+    }
+    @Override
+    public void cancel() {
+        running = false;
+    }
+}
\ No newline at end of file
Index: src/main/java/Chapter02_Customer_Source/TransforAggSum.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/main/java/Chapter02_Customer_Source/TransforAggSum.java b/src/main/java/Chapter02_Customer_Source/TransforAggSum.java
--- a/src/main/java/Chapter02_Customer_Source/TransforAggSum.java	
+++ b/src/main/java/Chapter02_Customer_Source/TransforAggSum.java	
@@ -1,0 +1,23 @@
+package Chapter02_Customer_Source;
+
+import org.apache.flink.api.java.functions.KeySelector;
+import org.apache.flink.streaming.api.datastream.DataStreamSource;
+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
+
+public class TransforAggSum {
+    public static void main(String[] args) throws Exception{
+        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
+        env.setParallelism(1);
+
+        DataStreamSource<Event> stream = env.fromElements(new Event("11", "22", 3000L));
+
+        stream.keyBy(new KeySelector<Event, Object>() {
+            @Override
+            public Object getKey(Event event) throws Exception {
+                return event.user;
+            }
+        }).max("timestamp").print();
+
+        env.execute();
+    }
+}
Index: src/main/java/Chapter02_Customer_Source/Event.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/main/java/Chapter02_Customer_Source/Event.java b/src/main/java/Chapter02_Customer_Source/Event.java
--- a/src/main/java/Chapter02_Customer_Source/Event.java	
+++ b/src/main/java/Chapter02_Customer_Source/Event.java	
@@ -1,0 +1,26 @@
+package Chapter02_Customer_Source;
+
+import java.sql.Timestamp;
+
+public class Event {
+
+    public String user;
+    public String url;
+    public Long timestamp;
+
+    public Event(String user, String url, Long timestamp) {
+        this.user = user;
+        this.url = url;
+        this.timestamp = timestamp;
+
+    }
+
+    @Override
+    public String toString() {
+     return "Event{" +
+                "user ='" + user + '\'' +
+                ", url = '" + url + '\'' +
+                ", timestamp = '" + new Timestamp(timestamp) +
+     '}';
+    }
+}
Index: src/main/java/chapter01/envent.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/main/java/chapter01/envent.java b/src/main/java/chapter01/envent.java
--- a/src/main/java/chapter01/envent.java	
+++ b/src/main/java/chapter01/envent.java	
@@ -1,0 +1,27 @@
+package chapter01;
+
+import java.sql.Timestamp;
+
+public class envent {
+    public String user;
+    public String url;
+    public Long timestamp;
+
+    public envent() {
+    }
+
+    public envent(String user, String url, Long timestamp) {
+        this.user = user;
+        this.url = url;
+        this.timestamp = timestamp;
+    }
+
+    @Override
+    public String toString() {
+        return "envent{" +
+                "user='" + user + '\'' +
+                ", url='" + url + '\'' +
+                ", timestamp=" + new Timestamp(timestamp)  +
+                '}';
+    }
+}
Index: src/main/java/Chapter02_Customer_Source/TransforFilter.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/main/java/Chapter02_Customer_Source/TransforFilter.java b/src/main/java/Chapter02_Customer_Source/TransforFilter.java
--- a/src/main/java/Chapter02_Customer_Source/TransforFilter.java	
+++ b/src/main/java/Chapter02_Customer_Source/TransforFilter.java	
@@ -1,0 +1,27 @@
+package Chapter02_Customer_Source;
+
+
+import org.apache.flink.streaming.api.datastream.DataStreamSource;
+import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;
+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
+
+public class TransforFilter {
+    public static void main(String[] args) throws Exception{
+        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
+        env.setParallelism(1);
+
+        //0, 我这里懒的去写了，直接添加了一个SourceFunction来生成数据；
+        DataStreamSource<Event> stream = env.addSource(new Parallelism_Source()).setParallelism(2);
+
+        //1. 可以是实现了FilterFunction的类的对象；
+        SingleOutputStreamOperator<Event> filter1 = stream.filter(new Filter_Function());
+
+        //2,传入一个Lambda FilterFunction的接口
+        SingleOutputStreamOperator<Event> filter2 = stream.filter(data -> data.user.equals("Ling"));
+
+        filter1.print();
+        filter2.print("Lambda: Ling");
+        env.execute();
+    }
+
+}
Index: src/main/java/Chapter02_Customer_Source/Filter_Function.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/main/java/Chapter02_Customer_Source/Filter_Function.java b/src/main/java/Chapter02_Customer_Source/Filter_Function.java
--- a/src/main/java/Chapter02_Customer_Source/Filter_Function.java	
+++ b/src/main/java/Chapter02_Customer_Source/Filter_Function.java	
@@ -1,0 +1,12 @@
+package Chapter02_Customer_Source;
+
+
+import org.apache.flink.api.common.functions.FilterFunction;
+
+public class Filter_Function implements FilterFunction<Event> {
+
+    @Override
+    public boolean filter(Event event) throws Exception {
+        return event.user.equals("Bob");
+    }
+}
\ No newline at end of file
Index: src/main/java/Chapter02_Customer_Source/TransforFilterMap.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/main/java/Chapter02_Customer_Source/TransforFilterMap.java b/src/main/java/Chapter02_Customer_Source/TransforFilterMap.java
--- a/src/main/java/Chapter02_Customer_Source/TransforFilterMap.java	
+++ b/src/main/java/Chapter02_Customer_Source/TransforFilterMap.java	
@@ -1,0 +1,64 @@
+package Chapter02_Customer_Source;
+
+
+import org.apache.flink.api.common.functions.FlatMapFunction;
+import org.apache.flink.api.common.typeinfo.TypeHint;
+import org.apache.flink.api.common.typeinfo.TypeInformation;
+import org.apache.flink.streaming.api.datastream.DataStreamSource;
+import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;
+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
+import org.apache.flink.streaming.api.functions.source.ParallelSourceFunction;
+import org.apache.flink.util.Collector;
+
+public class TransforFilterMap {
+    public static void main(String[] args) throws Exception {
+        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
+        env.setParallelism(1);
+
+
+        //1， 添加一个AddSource方法，其实就是我的数据源；
+        DataStreamSource<Event> filterMap = env.addSource(new Parallelism_Source()).setParallelism(1);
+
+        //2, 实现一个自定义FilterMapFunction，其实就是调用一个通用的方法，方法为FilerMap
+        SingleOutputStreamOperator<String> stringSingleOutputStreamOperator1 = filterMap.flatMap(new FilterMap_Function());
+
+
+        //3, 实现一个匿名函数的FilterMapFunction，其实就是不用在用调用别的方法来实现；
+        SingleOutputStreamOperator<Object> stringSingleOutputStreamOperator2 = filterMap.flatMap(new FlatMapFunction<Event, Object>() {
+            @Override
+            public void flatMap(Event event, Collector<Object> collector) throws Exception {
+                collector.collect(event.user);
+                collector.collect(event.url);
+                collector.collect(event.timestamp.toString());
+            }
+        }).returns(new TypeHint<Object>() {
+            @Override
+            public TypeInformation<Object> getTypeInfo() {
+                return super.getTypeInfo();
+            }
+        });
+
+        //4, 实现一个Lambda FilterMapFunction
+        SingleOutputStreamOperator<String> stringSingleOutputStreamOperator3 = filterMap.flatMap((Event event, Collector<String> collector) -> {
+            if (event.user.equals("Bob"))
+                collector.collect(event.user);
+            else if (event.user.equals("Ling")) {
+                collector.collect(event.user);
+                collector.collect(event.url);
+                collector.collect(event.timestamp.toString());
+            }
+
+        }).returns(new TypeHint<String>() {
+            @Override
+            public TypeInformation<String> getTypeInfo() {
+                return super.getTypeInfo();
+            }
+        });
+
+          stringSingleOutputStreamOperator1.print("Custmoer FilterMapFunction：");
+          stringSingleOutputStreamOperator2.print("NonFilterMap：");
+          stringSingleOutputStreamOperator3.print("Lambda：");
+
+        env.execute();
+    }
+}
Index: src/main/java/Chapter02_Customer_Source/FilterMap_Function.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/main/java/Chapter02_Customer_Source/FilterMap_Function.java b/src/main/java/Chapter02_Customer_Source/FilterMap_Function.java
--- a/src/main/java/Chapter02_Customer_Source/FilterMap_Function.java	
+++ b/src/main/java/Chapter02_Customer_Source/FilterMap_Function.java	
@@ -1,0 +1,16 @@
+package Chapter02_Customer_Source;
+
+import org.apache.flink.api.common.functions.FlatMapFunction;
+import org.apache.flink.util.Collector;
+
+public class FilterMap_Function implements FlatMapFunction<Event,String> {
+
+
+    @Override
+    public void flatMap(Event event, Collector<String> collector) throws Exception {
+        collector.collect(event.user);
+        collector.collect(event.url);
+        collector.collect(event.timestamp.toString());
+
+    }
+}
Index: src/main/java/chapter01/SourceTest.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/main/java/chapter01/SourceTest.java b/src/main/java/chapter01/SourceTest.java
--- a/src/main/java/chapter01/SourceTest.java	
+++ b/src/main/java/chapter01/SourceTest.java	
@@ -1,0 +1,65 @@
+package chapter01;
+
+import com.alibaba.ververica.cdc.debezium.internal.DebeziumChangeConsumer;
+import org.apache.flink.api.common.serialization.SimpleStringSchema;
+import org.apache.flink.streaming.api.datastream.DataStreamSource;
+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
+import org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer;
+
+import java.lang.reflect.Array;
+import java.util.ArrayList;
+import java.util.Properties;
+
+public class SourceTest {
+    public static void main(String[] args) throws Exception{
+
+        // 1, 创建执行环境
+        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
+        env.setParallelism(1);
+
+        //2, 从文件直接读取
+        DataStreamSource<String> Stream1 = env.readTextFile("D:\\01_Code\\YumchinaFlink\\input\\words.txt");
+
+        //3, 代码当中嵌入包装成一个集合类型
+        ArrayList<Integer> nums = new ArrayList<>();
+        nums.add(2);
+        nums.add(3);
+        DataStreamSource<Integer> Stream2 = env.fromCollection(nums);
+
+        //--------------------------------------------------------------
+        ArrayList<envent> envents = new ArrayList<>();
+        envents.add(new envent("Bob","/home",4300L));
+        envents.add(new envent("Marry","/user",9999L));
+        DataStreamSource<envent> Stream3 = env.fromCollection(envents);
+
+        //3, 从元素读取数据
+
+        DataStreamSource<envent> Stream4 = env.fromElements(
+                new envent("Ling", "/home", 4300L),
+                new envent("Jessies", "/user", 9999L)
+        );
+
+        //4, 从Socket读取数据
+//        DataStreamSource<String> socketSource = env.socketTextStream("localhost", 7777);
+
+
+        //5, 从kafka读取数据
+        Properties properties = new Properties();
+        properties.setProperty("bootstrap.servers","0.0.0.0:9092");
+        properties.setProperty("group.id", "consumer-group");
+        properties.setProperty("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
+        properties.setProperty("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
+        properties.setProperty("auto.offset.reset", "latest");
+
+        DataStreamSource<String> kafkaStream = env.addSource(new FlinkKafkaConsumer<String>("clicks", new SimpleStringSchema(), properties));
+
+//        Stream1.print();
+//        Stream2.print("nums");
+//        Stream3.print("Envents");
+//        Stream4.print("Elements");
+        kafkaStream.print();
+//        socketSource.print("Stream");
+        env.execute();
+
+    }
+}
Index: src/main/java/Chapter02_Customer_Source/ClickSource.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/main/java/Chapter02_Customer_Source/ClickSource.java b/src/main/java/Chapter02_Customer_Source/ClickSource.java
--- a/src/main/java/Chapter02_Customer_Source/ClickSource.java	
+++ b/src/main/java/Chapter02_Customer_Source/ClickSource.java	
@@ -1,0 +1,36 @@
+package Chapter02_Customer_Source;
+
+
+//自定义一个方法来随机生成数据；
+
+import org.apache.flink.streaming.api.functions.source.SourceFunction;
+import java.util.Calendar;
+import java.util.Random;
+
+public class ClickSource implements SourceFunction<Event> {
+    //声明标识位
+    private boolean running = true;
+    @Override
+    public void run(SourceContext<Event> ctx) throws Exception {
+
+        //随机生成器
+        Random random = new Random();
+        //定义字段选取的数据集
+        String[] users = {"Ling","Bob","Gary"};
+        String[] urls = {"./home","./cart","./fav","./prod?id=100","./prod?id=200"};
+
+
+        //循环生成数据
+        while (running){
+            String user = users[random.nextInt(users.length)];
+            String url = urls[random.nextInt(urls.length)];
+            Long timestamp = Calendar.getInstance().getTimeInMillis();
+            ctx.collect(new Event(user,url,timestamp));
+            Thread.sleep(1000L);
+        }
+    }
+    @Override
+    public void cancel() {
+        running = false;
+    }
+}
diff --git a/src/main/java/yumchina/wc/BoundedStreamWordCount.java b/src/main/java/yumchina/wc/BoundedStreamWordCount.java
deleted file mode 100644
diff --git a/src/main/java/yumchina/postgresql/csp_postgresql_cdc.java b/src/main/java/yumchina/postgresql/csp_postgresql_cdc.java
deleted file mode 100644
diff --git a/src/main/java/yumchina/wc/StreamWordCount.java b/src/main/java/yumchina/wc/StreamWordCount.java
deleted file mode 100644
diff --git a/src/main/java/yumchina/wc/StreamWordCount_1.java b/src/main/java/yumchina/wc/StreamWordCount_1.java
deleted file mode 100644
diff --git a/src/main/java/yumchina/wc/BatchWordCount.java b/src/main/java/yumchina/wc/BatchWordCount.java
deleted file mode 100644
